#!/bin/bash

# Copyright 2019 ThoughtSpot
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation
# files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy,
# modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT
# OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

# This file defines all of the settings for running a single load from a directory (and optionally sub-directories) using the
# load_files bash script.  You should be able to modify this file and use with load_file with no additonal modification.

# NOTE that the variables below are generally assumed to exist.  Deleting a variable rather than simply changing the value may
# cause errors in the load script.

declare -r DATA_FILE_EXTENSION=".csv"                    # extension for files to be loaded.
declare -r ROOT_DIR="/Users/misha.beek/"                 # Root where files for loading are located.
declare -r DATA_DIR=${ROOT_DIR}/data                     # location for the data to load.  Write files to load here.
declare -r RESULTS_EMAIL=("you@thoughtspot.com")         # email addresses to send the results to.
declare -r DATABASE_NAME="YOUR_DB_NAME"                  # database name.  Only one currently support per config.
declare -r DEFAULT_SCHEMA_NAME="falcon_default_schema"   # default schema name.
declare -r IGNORE_DIRS=(loaded test old file_backup)     # list of directories to ignore files to load.
declare -r NBR_DAYS_TO_KEEP_OLD_FILES=7                  # must be integer, set to blank to not remove old archives.
declare -r MOVE_LOADED_FILES="mv"                        # Command for files that were loaded.  Either "mv" or "cp" or "echo".
declare -r TRUNCATE_BEFORE_LOAD="false"                  # If "true", tables will be truncated when first loaded.  Useful if parts exist.
declare -r ARCHIVE_DATA="always"                         # Whether the data should be archived in the old folder. 
                                                         # For large data sets this can take considerable time and space. Valid options: 
                                                         # - always              : Files are always archived, tarred etc
                                                         # - onerror    : Files are archived when one of the files in the load failed
                                                         # - onbad               : Files are archived when one of the files generated bad records
                                                         # - never          : Files are never archived

# queries to run before loading a table
archive_date=`date --date="7 days ago" +%Y-%m-%d`
declare -A table_queries=()
#declare -A table_queries=(
#        ["interactions_bookings"]="delete from hilton.falcon_default_schema.interactions_bookings where date_id>='$archive_date'"
#)

# if using a semaphore file to control the start, set it here.  Set to "" if not using.
declare -r SEMAPHORE_FILE_NAME="stage_done"              # name of a file that indicates all staging files are loaded.

# Set any parts of the names that will be stripped from the file name to determine the table name. Patters separated by spaces.
SED_PATTERNS=("00.*" "historical_")

# Get the cluster name for cluster specific logging.
if hash tscli 2>/dev/null; then
  declare -r CLUSTER_NAME="`tscli cluster status | grep 'Cluster name' | sed 's/^.*: //' | sed 's/ /_/'`"
else
  declare -r CLUSTER_NAME="no_cluster_on_`hostname -s`"
fi

# TSLOAD flags.
# TODO set the flags for your environment.  The assumption is that all files have the same format.  If you have different
# formats, consider multiple configuration files and loads.
#declare -r DEFAULT_EMPTY_TARGET="--empty_target"                       # either --empty_target or ""
declare -r DEFAULT_EMPTY_TARGET=""                                     # either --empty_target or ""
declare -r SOURCE_DATA_FORMAT=csv                                      # either csv or delimited.
declare -r FIELD_SEPARATOR=","                                         # field separator in the data.
declare -r MAX_IGNORED_ROWS=0                                          # maximum rows to ignore.  0 recommended for production.
declare -r HAS_HEADER_ROW="true"                                       # true if there is a header row to ignore.
declare -r NULL_VALUE=""                                               # value in the data for NULLs
declare -r DATE_FORMAT="%Y%m%d"                                        # format for parsing dates
declare -r DATE_TIME_FORMAT="%Y%m%d %H:%M:%S"                          # format for parsing date/times
declare -r BOOLEAN_REPRESENTATION="True_False"                         # Boolean representation as TRUE_FALSE

# The following can be modified, but typically don't need to be.
declare -r THE_DATE_TIME="`date +"%Y-%m-%d_%H%M%S_%Z"`"                # date and time to use for load name.
declare -r LOG_DIR=${ROOT_DIR}/logs/historical                         # directory to store load logs.
declare -r OLD_DIR_ROOT=${ROOT_DIR}/old/historical                     # the 'root' folder for the old_dir (only used for clean-up)
declare -r OLD_DIR="${OLD_DIR_ROOT}/${THE_DATE_TIME}"                  # directory to store loaded files and bad records to.
declare -r TEMP_RESULTS_FILE="/tmp/$$.results"                         # temp folder for detailed results.
declare -r TEMP_RESULTS_SUMMARY_FILE="/tmp/$$.results.summary"         # temp folder for results summary.
declare -r RESULTS_FILE="${LOG_DIR}/${CLUSTER_NAME}-results-${THE_DATE_TIME}.txt" # stores the results of the data load.
declare -r LOADING_FILE="${DATA_DIR}/loading"                          # flag to indicate we are currently loading.
declare -r V_LEVEL=0                                                   # logging verbosity level.  0-6.  0 recommended for production.

